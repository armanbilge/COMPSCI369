{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This IPython notebook represents my written report and source code for COMPSCI 369 Assignment 3. To generate a PDF version of this report, simply type `rake` at the command line. The generated report can be found at `report.pdf`. Please note that you will need the following software installed.\n",
    "\n",
    "* Graphviz\n",
    "* IPython 3\n",
    "* \\LaTeX\n",
    "* matplotlib\n",
    "* NumPy\n",
    "* pandoc\n",
    "* PDFtk\n",
    "* R\n",
    "* Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_pdf, set_matplotlib_formats\n",
    "import itertools as it\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('pdf')\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from Tree import Tree\n",
    "from Node import Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following HMM for secondary structure in protein sequences. The secondary structure at a residue is either an $\\alpha$-helix, $\\beta$-strand, or a loop, represented by the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATES = ('H', 'E', 'T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state transitions are described by the following diagram. The initial state for the sequence is distributed uniformly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = {\n",
    "    'H': {'H': 15/16, 'E': 3/160, 'T': 7/160},\n",
    "    'E': {'H': 1/15, 'E': 5/6, 'T': 1/10},\n",
    "    'T': {'H': 1/8, 'E': 1/8, 'T': 3/4},\n",
    "}\n",
    "\n",
    "edges = ('{} -> {} [label = {:.5g}];'.format(x, y, A[x][y])\n",
    "         for x, y in it.product(STATES, repeat=2))\n",
    "hmm = 'digraph {{{}}}'.format(''.join(edges)).encode()\n",
    "display_pdf(subprocess.check_output(['dot', '-Tpdf'], input=hmm), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A state may emit a hydrophobic, hydrophilic, or neutral amino acid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYMBOLS = ('B', 'I', 'N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emission probabilities for each state are given by the following table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E = {\n",
    "    'H': {'B': 0.3, 'I': 0.5, 'N': 0.2},\n",
    "    'E': {'B': 0.55, 'I': 0.15, 'N': 0.3},\n",
    "    'T': {'B': 0.1, 'I': 0.4, 'N': 0.5},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       |**B**|**I**|**N**|\n",
    "|:-----:|:---:|:---:|:---:|\n",
    "| **H** | 0.3 | 0.5 | 0.2 |\n",
    "| **E** | 0.55| 0.15| 0.3 |\n",
    "| **T** | 0.1 | 0.4 | 0.5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simulate a sequence of length 200 under the HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def d2l(d, K):\n",
    "    return [d[k] for k in K]\n",
    "\n",
    "def simulate_hmm(length):\n",
    "    states = []\n",
    "    symbols = []\n",
    "    if length > 0:\n",
    "        states.append(np.random.choice(STATES))\n",
    "        symbols.append(np.random.choice(SYMBOLS, p=d2l(E[states[-1]], SYMBOLS)))\n",
    "        for _ in range(1, length):\n",
    "            states.append(np.random.choice(STATES, p=d2l(A[states[-1]], STATES)))\n",
    "            symbols.append(np.random.choice(SYMBOLS, p=d2l(E[states[-1]], SYMBOLS)))\n",
    "    return states, symbols\n",
    "\n",
    "states, symbols = simulate_hmm(200)\n",
    "print('\\n'.join(','.join(s) for s in np.array_split(states, 5)))\n",
    "print()\n",
    "print('\\n'.join(','.join(s) for s in np.array_split(symbols, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate the logarithm of the joint probability $\\log{\\left(P\\left(x,\\pi\\right)\\right)}$ of this sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joint_logp(states, symbols):\n",
    "    logp = 0\n",
    "    if len(states) > 0:\n",
    "        logp -= np.log2(len(STATES))\n",
    "        logp += np.log2(E[states[0]][symbols[0]])\n",
    "        for i in range(1, len(states)):\n",
    "            logp += np.log2(A[states[i-1]][states[i]])\n",
    "            logp += np.log2(E[states[i]][symbols[i]])\n",
    "    return logp\n",
    "\n",
    "joint_logp(states, symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that\n",
    "$$\\pi = H,H,H,H,H,T,T,E,E,E,H,H,H,H,H,H,E,E,E,E,E,E$$\n",
    "$$x = N,I,N,B,N,I,I,B,N,I,B,B,I,N,B,I,I,N,B,B,N,B$$\n",
    "then $\\log\\left(P\\left(x,\\pi\\right)\\right)$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = ['H','H','H','H','H','T','T','E','E','E','H','H','H','H','H','H','E','E','E','E','E','E']\n",
    "x = ['N','I','N','B','N','I','I','B','N','I','B','B','I','N','B','I','I','N','B','B','N','B']\n",
    "joint_logp(pi, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log probability of the simulated symbols is given by the forward algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log2sum(x):\n",
    "    x = np.array(x)\n",
    "    return x[0] + np.log2(np.sum(np.power(2, x - x[0])))\n",
    "\n",
    "def forward(x):\n",
    "    logp = np.array([0.0] * len(STATES))\n",
    "    if len(x) > 0:\n",
    "        for i, st in enumerate(STATES):\n",
    "            logp[i] = np.log2(E[st][x[0]]) - np.log2(len(STATES))\n",
    "        for sy in x[1:]:\n",
    "            prev = logp\n",
    "            logp = np.array([0.0] * len(STATES))\n",
    "            for i, st in enumerate(STATES):\n",
    "                logp[i] = np.log2(E[st][sy]) \\\n",
    "                    + log2sum([prev[j] + np.log2(A[k][st]) for j, k in enumerate(STATES)])\n",
    "    return log2sum(logp)\n",
    "\n",
    "forward(symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $x$ defined as above, $\\log{\\left(P\\left(x\\right)\\right)}$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both of these examples, $P\\left(x, \\pi\\right) \\leq P\\left(x\\right)$. This is true in general because\n",
    "$$P\\left(x\\right) = \\sum_{\\pi^\\prime}{P\\left(x, \\pi^\\prime\\right)} = \\sum_{\\pi^\\prime\\neq\\pi}{P\\left(x, \\pi^\\prime\\right)} + P\\left(x, \\pi\\right) \\geq P\\left(x, \\pi\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the log of the forward matrix $F$ to perform the first step of the stochastic traceback algorithm by noting that\n",
    "$$P\\left(\\pi_L = k \\mid x\\right) = \\frac{f_k\\left(L\\right)}{P\\left(x\\right)} = \\exp{\\left(F_k\\left(L\\right) - \\log{\\left(P\\left(x\\right)\\right)}\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can simulate trees on $n$ taxa according to the Yule model with branching parameter $\\lambda$ by using the point process formalisation described by Tanja Gernhard (2008. The conditioned reconstructed process. _Journal of Theoretical Biology_, 253.4. pp. 769â€“778. doi:[`10.1016/j.jtbi.2008.04.005`](http://doi.org/10.1016/j.jtbi.2008.04.005))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we sample the time of origin $t$ by drawing $u$ uniformly at random from the interval $\\left[0,1\\right)$ and transforming it by\n",
    "$$Q^{-1}_{or}\\left(u\\right) = - \\frac{\\log{\\left(1 - \\sqrt[n]{u}\\right)}}{\\lambda}$$\n",
    "where $Q_{or}\\left(t \\mid n\\right)$ is given in corollary 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_t(n, lambd):\n",
    "    return - np.log(1 - np.power(np.random.random(), 1/n)) / lambd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sample $n-1$ speciation times $s$ by drawing $u$ uniformly at random from the the interval $\\left[0,1\\right)$ and transforming it by\n",
    "$$F^{-1}\\left(u\\right) = - \\frac{\\log{\\left(1 - \\left(1 - \\exp{\\left(-\\lambda t\\right)}\\right) u \\right)}}{\\lambda}$$\n",
    "for each, where $F\\left(s \\mid t\\right)$ is given in section 2.1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_s(n, lambd):\n",
    "    t = random_t(n, lambd)\n",
    "    s = - np.log(1 - (1 - np.exp(-lambd * t)) * np.random.random(n-1)) / lambd\n",
    "    s.sort() # Most recent to oldest speciation times\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate a tree, we create a parent node with the next speciation time and assign it two children chosen uniformly at random from the available nodes. Then we remove these children from the available nodes and add the parent. We repeat this procedure $n-1$ times until there is only one available node, the root of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_tree(n, lambd):\n",
    "    nodes = []\n",
    "    for i in map(str, range(1, n+1)):\n",
    "        node = Node(i)\n",
    "        node.set_height(0)\n",
    "        nodes.append(node)\n",
    "    for s in random_s(n, lambd):\n",
    "        node = Node()\n",
    "        i, j = np.random.choice(nodes, replace=False, size=2)\n",
    "        node.set_height(s)\n",
    "        node.add_child(i)\n",
    "        node.add_child(j)\n",
    "        nodes.remove(i)\n",
    "        nodes.remove(j)\n",
    "        nodes.append(node)\n",
    "    return Tree(nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simulate $1000$ trees with $n = 10$ and $\\lambda = 1$ and compute their mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean([simulate_tree(10, 1).get_root().get_height() for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statistic agrees with the theoretical mean $1.93$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep this notebook self-contained, I implement my own tree plotting function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_node_xy(node, counter=it.count()):\n",
    "    node.x = node.get_height()\n",
    "    if node.is_leaf():\n",
    "        node.y = next(counter)\n",
    "    else:\n",
    "        children = node.get_children()\n",
    "        for child in children:\n",
    "            compute_node_xy(child, counter)\n",
    "        node.y = np.mean([c.y for c in children])\n",
    "\n",
    "def plot_node(node):\n",
    "    if node.is_leaf():\n",
    "        plt.text(node.x, node.y, ' ' + node.get_label(),\n",
    "                 {'ha':'left', 'va':'center'})\n",
    "    else:\n",
    "        children = node.get_children()\n",
    "        plt.plot([node.x] * 2, [min(c.y for c in children),\n",
    "                                max(c.y for c in children)], 'k')\n",
    "        for child in children:\n",
    "            plt.plot([node.x, child.x], [child.y] * 2, 'k')\n",
    "            plot_node(child)\n",
    "\n",
    "def plot_tree(tree):\n",
    "    root = tree.get_root()\n",
    "    compute_node_xy(root)\n",
    "    plt.plot([root.x, root.x + root.x/16], [root.y] * 2, 'k')\n",
    "    plot_node(root)\n",
    "    lc = tree.get_leaf_count()\n",
    "    plt.ylim(- lc / 16, 17/16 * lc - 1)\n",
    "    axes = plt.gca()\n",
    "    axes.invert_xaxis()\n",
    "    axes.yaxis.set_visible(False)\n",
    "    axes.set_frame_on(False)\n",
    "    axes.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simulate and plot a tree with $n = 10$ and $\\lambda = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = simulate_tree(10, 1)\n",
    "plot_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we simulate sequences down the tree according to the Jukes-Cantor model. At the root node, we draw a random sequence of length $L$ according to the base equilibrium frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASES = ('A', 'C', 'G', 'T')\n",
    "def random_sequence(length):\n",
    "    return ''.join(np.random.choice(BASES, size=length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence at a non-root node simulated by mutating its parent node's sequence for the time given by the difference in their heights. Over time $t$ a nucleotide $x$ in a sequence $S$ mutates with rate $\\mu$ to each of the other bases with probability\n",
    "$$p_{i \\neq j} = \\frac{1}{4} - \\frac{1}{4} \\exp{\\left(-\\frac{4}{3} \\mu t\\right)}$$\n",
    "or stays the same with probability\n",
    "$$p_{i = j} = \\frac{1}{4} + \\frac{3}{4} \\exp{\\left(-\\frac{4}{3} \\mu t\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutate_sequence(S, mu, t):\n",
    "    ieqj = 1/4 + 3/4 * np.exp(-4/3 * mu * t)\n",
    "    ineqj = 1/4 - 1/4 * np.exp(-4/3 * mu * t)\n",
    "    p = {b : [ieqj if c == b else ineqj for c in BASES] for b in BASES}\n",
    "    return ''.join(np.random.choice(BASES, p=p[x]) for x in S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the simulation recurses for each of a non-leaf node's children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_sequences(node, mu, length=None):\n",
    "    if length:\n",
    "        node = node.get_root()\n",
    "        node.set_sequence(random_sequence(length))\n",
    "    if not node.is_root():\n",
    "        parent = node.get_parent()\n",
    "        t = parent.get_height() - node.get_height()\n",
    "        S = mutate_sequence(parent.get_sequence(), mu, t)\n",
    "        node.set_sequence(S)\n",
    "    if not node.is_leaf():\n",
    "        for child in node.get_children():\n",
    "            simulate_sequences(child, mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simulate sequences of length $L = 20$ with mutation rate $\\mu = 0.5$ along our previously simulated tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simulate_sequences(tree, 0.5, 20)\n",
    "\n",
    "def get_sequences(tree):\n",
    "    return sorted(tree.get_leaves(), key=lambda l: int(l.get_label()))\n",
    "sequences = get_sequences(tree)\n",
    "\n",
    "for seq in sequences:\n",
    "    print('{:<3}: {}'.format(seq.get_label(), seq.get_sequence()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jukes-Cantor distance $d_{xy}$ between two sequences $x$ and $y$ is given by\n",
    "$$d_{xy} = -\\frac{3}{4} \\log{\\left(1 - \\frac{4}{3}f_{xy}\\right)}$$\n",
    "where $f_{xy}$ is the fraction of differing sites between $x$ and $y$ and is given by\n",
    "$$f_{xy} = \\min{\\left(\\frac{D_{xy}}{L}, \\frac{3}{4} - \\frac{1}{L}\\right)}$$\n",
    "where $D_{xy}$ is the Hamming distance between $x$ and $y$ and $L$ is the length of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def D(x, y):\n",
    "    return sum(a != b for a, b in zip(x, y))\n",
    "\n",
    "def f(x, y):\n",
    "    L = len(x)\n",
    "    return min(D(x,y) / L, 3/4 - 1/L)\n",
    "\n",
    "def d(x, y):\n",
    "    return - 3/4 * np.log(1 - 4/3 * f(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the distance matrix for a set of sequences by computing $d_{xy}$ for all pairs $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_matrix(sequences):\n",
    "    sequences = list(map(Node.get_sequence, sequences))\n",
    "    return [[d(x, y) for y in sequences] for x in sequences]\n",
    "\n",
    "def distance_matrix_file(sequences, filename):\n",
    "    d = distance_matrix(sequences)\n",
    "    with open(filename, 'w') as file:\n",
    "        for seq, row in zip(sequences, d):\n",
    "            row = [seq.get_label()] + list(map(str, row))\n",
    "            print(','.join(row), file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the distance matrix for our previously simulated sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in distance_matrix(sequences):\n",
    "    print('  '.join(map('{:.3f}'.format, [x+0 for x in row])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we compare the quality of UPGMA reconstruction of the previously simulated tree for simulated sequences of lengths $L \\in \\left\\{20, 50, 200\\right\\}$ mutating with rate $\\mu = 0.2$. First we create the distance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for L in (20, 50, 200):\n",
    "    simulate_sequences(tree, 0.2, L)\n",
    "    sequences = get_sequences(tree)\n",
    "    distance_matrix_file(sequences, 'distL{}.csv'.format(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the provided script `doUPGMA.R` and view the reconstructed trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subprocess.call(['Rscript', 'doUPGMA.R'])\n",
    "output = 'UPGMAtree_%d.pdf'\n",
    "subprocess.call(['pdftk', 'UPGMAtrees.pdf', 'burst', 'output', output])\n",
    "for i in range(1, 4):\n",
    "    with open(output % i, 'rb') as pdf:\n",
    "        display_pdf(pdf.read(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the quality of the reconstruction improves as the sequence length increases. In particular, the accuracy of the node heights improves substantially when considering more sequence data (it is important to note that the reconstructed heights $\\mathbf{\\hat{h}}$ are not expected to exactly match the true heights $\\mathbf{h}$ but should be proportional such that $\\mathbf{\\hat{h}} = 2\\mu\\mathbf{h} = 0.4\\mathbf{h}$). However, there are often still errors in the reconstructed topology even when using sequences of length 200, especially in regions of the tree with old divergences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
