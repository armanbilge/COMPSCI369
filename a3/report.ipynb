{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This IPython notebook represents my written report and source code for COMPSCI 369 Assignment 3. To generate a PDF version of this report, simply type `rake` at the command line. The generated report can be found at `report.pdf`. Please note that you will need the following software installed.\n",
    "\n",
    "* Graphviz\n",
    "* IPython 3\n",
    "* \\LaTeX\n",
    "* matplotlib\n",
    "* NumPy\n",
    "* pandoc\n",
    "* R\n",
    "* Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_pdf\n",
    "import itertools as it\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from Tree import Tree\n",
    "from Node import Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following HMM for secondary structure in protein sequences. The secondary structure at a residue is either an $\\alpha$-helix, $\\beta$-strand, or a loop, represented by the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATES = ('H', 'E', 'T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state transitions are described by the following diagram. The initial state for the sequence is distributed uniformly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = {\n",
    "    'H': {'H': 15/16, 'E': 3/160, 'T': 7/160},\n",
    "    'E': {'H': 1/15, 'E': 5/6, 'T': 1/10},\n",
    "    'T': {'H': 1/8, 'E': 3/4, 'T': 1/8},\n",
    "}\n",
    "\n",
    "edges = ('{} -> {} [label = {:.5g}];'.format(x, y, A[x][y])\n",
    "         for x, y in it.product(STATES, repeat=2))\n",
    "hmm = 'digraph {{{}}}'.format(''.join(edges)).encode()\n",
    "display_pdf(subprocess.check_output(['dot', '-Tpdf'], input=hmm), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A state may emit a hydrophobic, hydrophilic, or neutral amino acid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMISSIONS = ('B', 'I', 'N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emission probabilities for each state are given by the following table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E = {\n",
    "    'H': {'B': 0.3, 'I': 0.5, 'N': 0.2},\n",
    "    'E': {'B': 0.15, 'I': 0.55, 'N': 0.3},\n",
    "    'T': {'B': 0.4, 'I': 0.1, 'N': 0.5},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       |**B**|**I**|**N**|\n",
    "|:-----:|:---:|:---:|:---:|\n",
    "| **H** | 0.3 | 0.5 | 0.2 |\n",
    "| **E** | 0.15| 0.55| 0.3 |\n",
    "| **T** | 0.4 | 0.1 | 0.5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simulate a sequence of length 200 under the HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def d2l(d, K):\n",
    "    return [d[k] for k in K]\n",
    "\n",
    "def simulate_hmm(length):\n",
    "    states = []\n",
    "    symbols = []\n",
    "    if length > 0:\n",
    "        states.append(np.random.choice(STATES))\n",
    "        symbols.append(np.random.choice(EMISSIONS, p=d2l(E[states[-1]], EMISSIONS)))\n",
    "        for _ in range(1, length):\n",
    "            states.append(np.random.choice(STATES, p=d2l(A[states[-1]], STATES)))\n",
    "            symbols.append(np.random.choice(EMISSIONS, p=d2l(E[states[-1]], EMISSIONS)))\n",
    "    return states, symbols\n",
    "\n",
    "states, symbols = simulate_hmm(200)\n",
    "print('\\n'.join(','.join(s) for s in np.array_split(states, 5)))\n",
    "print()\n",
    "print('\\n'.join(','.join(s) for s in np.array_split(symbols, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate the logarithm of the joint probability $\\log{\\left(P\\left(x,\\pi\\right)\\right)}$ of this sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joint_logp(states, symbols):\n",
    "    logp = 0\n",
    "    if len(states) > 0:\n",
    "        logp -= np.log2(len(STATES))\n",
    "        logp += np.log2(E[states[0]][symbols[0]])\n",
    "        for i in range(1, len(states)):\n",
    "            logp += np.log2(A[states[i-1]][states[i]])\n",
    "            logp += np.log2(E[states[i]][symbols[i]])\n",
    "    return logp\n",
    "\n",
    "joint_logp(states, symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that\n",
    "$$\\pi = H,H,H,H,H,T,T,E,E,E,H,H,H,H,H,H,E,E,E,E,E,E$$\n",
    "$$x = N,I,N,B,N,I,I,B,N,I,B,B,I,N,B,I,I,N,B,B,N,B$$\n",
    "then $\\log\\left(P\\left(x,\\pi\\right)\\right)$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = ['H','H','H','H','H','T','T','E','E','E','H','H','H','H','H','H','E','E','E','E','E','E']\n",
    "x = ['N','I','N','B','N','I','I','B','N','I','B','B','I','N','B','I','I','N','B','B','N','B']\n",
    "joint_logp(pi, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log probability of the simulated symbols is given by the forward algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log2sum(x):\n",
    "    x = np.array(x)\n",
    "    return x[0] + np.log2(np.sum(np.power(2, x - x[0])))\n",
    "\n",
    "def forward(x):\n",
    "    logp = np.array([0.0] * len(STATES))\n",
    "    if len(x) > 0:\n",
    "        for i, st in enumerate(STATES):\n",
    "            logp[i] = np.log2(E[st][x[0]]) - np.log2(len(STATES))\n",
    "        for sy in x[1:]:\n",
    "            prev = logp\n",
    "            logp = np.array([0.0] * len(STATES))\n",
    "            for i, st in enumerate(STATES):\n",
    "                logp[i] = np.log2(E[st][sy]) \\\n",
    "                    + log2sum([prev[j] + np.log2(A[k][st]) for j,k in enumerate(STATES)])\n",
    "    return log2sum(logp)\n",
    "\n",
    "forward(symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $x$ defined as above, $\\log{\\left(P\\left(x\\right)\\right)}$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both of these examples, $P\\left(x, \\pi\\right) \\leq P\\left(x\\right)$. This is true in general because\n",
    "$$P\\left(x\\right) = \\sum_{\\pi^\\prime}{P\\left(x, \\pi^\\prime\\right)} = \\sum_{\\pi^\\prime\\neq\\pi}{P\\left(x, \\pi^\\prime\\right)} + P\\left(x, \\pi\\right) \\geq P\\left(x, \\pi\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the log of the forward matrix $F$ to perform the first step of the stochastic traceback algorithm by noting that\n",
    "$$P\\left(\\pi_L = k \\mid x\\right) = \\frac{f_k\\left(L\\right)}{P\\left(x\\right)} = \\exp{\\left(F_k\\left(L\\right) - \\log{\\left(P\\left(x\\right)\\right)}\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can simulate trees on $n$ taxa according to the Yule model with branching parameter $\\lambda$ by using the point process formalisation described by Tanja Gernhard (2008. The conditioned reconstructed process. _Journal of Theoretical Biology_, 253.4. pp. 769â€“778. doi:[`10.1016/j.jtbi.2008.04.005`](http://doi.org/10.1016/j.jtbi.2008.04.005))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we sample the time of origin $t$ by drawing $u$ uniformly at random from the interval $\\left[0,1\\right)$ and transforming it by\n",
    "$$Q^{-1}_{or}\\left(u\\right) = - \\frac{\\log{\\left(1 - \\sqrt[n]{u}\\right)}}{\\lambda}$$\n",
    "where $Q_{or}\\left(t \\mid n\\right)$ is given in corollary 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_t(n, lambd):\n",
    "    return - np.log(1 - np.power(np.random.random(), 1/n)) / lambd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sample $n-1$ speciation times $s$ by drawing $u$ uniformly at random from the the interval $\\left[0,1\\right)$ and transforming it by\n",
    "$$F^{-1}\\left(u\\right) = - \\frac{\\log{\\left(1 - \\left(1 - \\exp{\\left(-\\lambda t\\right)}\\right) u \\right)}}{\\lambda}$$\n",
    "for each, where $F\\left(s \\mid t\\right)$ is given in section 2.1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_s(n, lambd):\n",
    "    t = random_t(n, lambd)\n",
    "    s = - np.log(1 - (1 - np.exp(-lambd * t)) * np.random.random(n-1)) / lambd\n",
    "    s.sort() # Most recent to oldest speciation times\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate a tree, we create a parent node with the next speciation time and assign it two children chosen uniformly at random from the available nodes. Then we remove these children from the available nodes and add the parent. We repeat this procedure $n-1$ times until there is only one available node, the root of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_tree(n, lambd):\n",
    "    nodes = []\n",
    "    for i in map(str, range(n)):\n",
    "        node = Node(i)\n",
    "        node.set_height(0)\n",
    "        nodes.append(node)\n",
    "    for s in random_s(n, lambd):\n",
    "        node = Node()\n",
    "        i, j = np.random.choice(nodes, replace=False, size=2)\n",
    "        node.set_height(s)\n",
    "        node.add_child(i)\n",
    "        node.add_child(j)\n",
    "        nodes.remove(i)\n",
    "        nodes.remove(j)\n",
    "        nodes.append(node)\n",
    "    return Tree(nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simulate $1000$ trees with $\\lambda = 1$ and $n = 10$ and compute their mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean([simulate_tree(10, 1).get_root().get_height() for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statistic agrees with the theoretical mean $1.93$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep this notebook self-contained, I implement my own tree plotting function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_node_xy(node):\n",
    "    node.x = node.get_height()\n",
    "    if node.is_leaf():\n",
    "        node.y = int(node.get_label())\n",
    "    else:\n",
    "        children = node.get_children()\n",
    "        for c in children:\n",
    "            compute_node_xy(c)\n",
    "        node.y = sum(c.y for c in children) / len(children)\n",
    "\n",
    "def plot_node(node):\n",
    "    if node.is_leaf():\n",
    "        plt.text(node.x,\n",
    "                 node.y,\n",
    "                 node.get_label(),\n",
    "                 {'ha':'left', 'va':'center'},\n",
    "                 rotation=45)\n",
    "    else:\n",
    "        for c in node.get_children():\n",
    "            plt.plot()\n",
    "            plot_node(c)\n",
    "\n",
    "def plot_tree(tree):\n",
    "    plot_node(tree.get_root())\n",
    "    ax = plt.gca()\n",
    "    ax.invert_xaxis()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    ax.grid()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
